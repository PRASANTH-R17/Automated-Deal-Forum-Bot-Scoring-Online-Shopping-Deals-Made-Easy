# Import Libraries
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
import requests
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
from selenium.webdriver.chrome.options import Options
import urllib.request
import os
from telethon import TelegramClient, events
import re
from PIL import Image
from urllib.parse import quote
from datetime import datetime

# Open Normal Browser using Selenium. Here we use Chrome with the Chrome Debugger feature.
path = "D:\Web Scraping\chromedriver.exe"
chrome_options = Options()
chrome_options.add_experimental_option("debuggerAddress", "127.0.0.1:9199")
chrome_driver = path
driver = webdriver.Chrome(options=chrome_options)

# Function to shorten a URL using the bitly API.
def shorten_url(url):
    access_token = "073c6fa2ec6c3c9a8adba"
    api_url = "https://api-ssl.bitly.com/v4/shorten"
    headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
    data = {"long_url": url}
    response = requests.post(api_url, json=data, headers=headers)
    return "https://" + response.json()["id"] if response.ok else None

# Share Product in a Telegram channel along with an image.
# This function converts an image into a 1:1 ratio (square) with a white background.
def make_image_1to1():
    # Image download by download_image Function and Store in this Path
    # Image Input Path
    input_image_path = "D:\Web Scraping\Amazon Product Image\product_image.jpg"

    # After converting this image to 1:1, it is stored in this path (output Path)
    output_image_path = "D:\Web Scraping\Amazon Product Image\product_image.jpg"

    input_image = Image.open(input_image_path)
    desired_size = max(input_image.size)

    # Empty Space is filled with white color
    new_image = Image.new("RGB", (desired_size, desired_size), color="white")

    new_image.paste(input_image, ((desired_size - input_image.width) // 2, (desired_size - input_image.height) // 2))
    new_image.save(output_image_path)

    # Indication Message
    print("Image resized into 1:1 ratio")

# Function to send a message in Telegram automatically
def send_msg(formatted_caption):
    formatted_caption = quote(formatted_caption)

    # Telegram Bot API Token
    apiToken = "6530852668:AAHR9j"

    # Enter Group ID to which we want to send the message
    chID = "-1001759681"

    # Using this URL to send a text message with an image
    base_url = f'https://api.telegram.org/bot{apiToken}/sendphoto?chat_id={chID}&caption={formatted_caption}&parse_mode=Markdown'
    files = {'photo': open("D:\Web Scraping\Amazon Product Image\product_image.jpg", 'rb')}
    # The link is executed in the browser using the Requests Library
    req = requests.post(base_url, files=files)

    # Status Indication Message
    print("Message sent")
    print("Message Code:", req.status_code)

# Rarely Used Function
# If any problem occurs when retrieving Product Price, this function will be executed
def find_least_price(message):
    message = re.sub(r'(\.\d{2}\b|\(.*?\))', '', message)
    prices = re.findall(r'â‚¹\d{1,3}(?:,\d{3})*', message)
    price_values = [int(price.replace('â‚¹', '').replace(',', '')) for price in prices]
    least_price = min(price_values)
    print("Least price was found:", least_price)
    return 'â‚¹' + '{:,}'.format(least_price)

# Product Image Link is generated by Selenium
# After retrieving a link, the Image is downloaded using this function and URL
def download_image(url):

    # Downloaded Image Save Path
    save_path = r"D:\Web Scraping\Amazon Product Image"

    # Download Image Name
    image_name = "product_image"
    try:
        with urllib.request.urlopen(url) as response:
            image_data = response.read()

        # Join the specified save path with the desired image name to get the full path
        full_save_path = os.path.join(save_path, f"{image_name}.jpg")

        with open(full_save_path, "wb") as file:
            file.write(image_data)
    except Exception as e:
        print(f"Error downloading the image: {e}")
    else:
        print("Image downloaded successfully.")

    make_image_1to1()

# Product Image is downloaded using the download_image Function
# After the Message is sent, this Function deletes the Downloaded Image to Avoid Overriding
def delete_image():
    image_path = r"D:\Web Scraping\Amazon Product Image\product_image.jpg"
    try:
        os.remove(image_path)
    except OSError as e:
        print(f"Error deleting the image: {e}")
    else:
        print("Image deleted successfully.")

# Shorten a Product Title using ChatGPT
def chatGPT(msg):
    driver.get("https://chat.openai.com/")
    driver.find_element(By.ID, 'prompt-textarea').click()
    driver.find_element(By.ID, 'prompt-textarea').send_keys(msg)
    driver.find_element(By.XPATH, '//*[@id="__next"]/div[1]/div/div/main/div[2]/form/div/div/button').click()
    time.sleep(10)
    return driver.find_element(By.XPATH,'//*[@id="__next"]/div[1]/div/div/main/div[1]/div/div/div/div[2]/div/div[2]/div[1]/div/div/p').text

# miniPriceHistory + findProductSummary Both Function are Worked Simultaneously

# Function to retrieve product price history summary
def find_product_summary(product_link):
    driver.get("https://pricehistory.app/")

    driver.find_element(By.ID, "search").click()
    driver.find_element(By.ID, "search").send_keys(product_link)
    driver.find_element(By.ID, "search").send_keys(Keys.ENTER)

    time.sleep(3)
    summary = str(driver.find_element(By.XPATH, '//*[@id="price-summary"]/ul').text)

    try:
        return miniPriceHistory(summary)
    except:
        return summary

# Function to generate a shorter product price history summary
def miniPriceHistory(text):
    def replace_date(match):
        date_str = match.group()
        date_obj = datetime.strptime(date_str, '%dth %b %Y')
        formatted_date = date_obj.strftime('%d-%b-%y')
        return formatted_date

    updated_text = re.sub(r'\d{1,2}th \w+ \d{4}', replace_date, text)

    replacements = {
        "The lowest price": "Low price",
        "The average price": "Avg price",
        "The highest price": "High price",
        "The selling price": "Sell price",
        ".": "",
        "The": "",
    }

    for original, replacement in replacements.items():
        updated_text = updated_text.replace(original, replacement)

    print(updated_text.strip())
    return updated_text.strip()

# Main Function to retrieve all relevant data about the product
def scrape_amazon_data(link):
    driver.get(link)

    # Get Product Title
    title = driver.find_element(By.ID, "productTitle").text

    # Get Rating of the Product
    try:
        rating = driver.find_element(By.XPATH, '//*[@id="acrPopover"]/span[1]/a/span').text

        ratingCount = driver.find_element(By.ID, "acrCustomerReviewText").text
        ratingCount = ratingCount[0:ratingCount.index(" ")]
        ratingCount = f"({ratingCount})"
        rating = rating + " " + ratingCount
    except:
        rating = "Not found"

    # Get Image URL
    try:
        imageURL = driver.find_element(By.XPATH, '//*[@id="landingImage"]').get_attribute("src")
    except:
        imageURL = driver.find_element(
            By.XPATH, '//*[@id="main-image-container"]/ul/li[4]/span/span/div/img').get_attribute("src")

    # Get Product Current Price
    price = driver.find_element(By.CLASS_NAME, "a-price-whole").text

    # Convert Normal Links to Affiliated Link
    driver.find_element(
        By.XPATH, '//*[@id="amzn-ss-text-link"]/span/strong/a').click()
    time.sleep(3)
    try:
        affiliateLink = driver.find_element(
            By.ID, "amzn-ss-text-shortlink-textarea"
        ).text
        print("Affiliated Link was found")
    except:
        affiliateLink = shorten_url(link)
        print("Affiliated Link was not found so shorten link was executed")

    # Normal Link ( Long link ) is taken If any problem occurs to generate Affiliated Link
    if len(affiliateLink) == 0:
        print("Affiliated Link variable size is zero, so the normal link was taken")
        affiliateLink = link
    normal_link = driver.current_url

    # Get Short Title
    try:
        shortTitle = (
            "Make this title easy, too short and simple, avoid keywords (introducing, newly launched, get)"+ f"'{title}'")
        shortTitle = chatGPT(shortTitle)
        print(shortTitle)
        shortTitle = shortTitle[1 : len(shortTitle) - 1]
        print("Title was shortened using ChatGPT")
    except:
        shortTitle = title
        print("Title short ChatGPT was not working, so the normal title was taken")

    if len(shortTitle) == 0:
        print("Normal Title was taken")
        shortTitle = title

    try:
        # Product price History Link is Available
        productSummary = find_product_summary(normal_link)
        productSummaryStatus = True
        caption = (
            f"ðŸŒŸ{shortTitle} \n\nâœ… Price: *Rs.{price}/-* \n\nðŸŒŸ Rating : {rating}\n\nðŸ”— {affiliateLink} \n\n*ðŸ“ˆProduct price History* : \n\n_{productSummary}_"
        )
        print("Product price summary is Available")
        return [caption, imageURL]
    except Exception as error:
        # Product price History Link is Not Available
        productSummaryStatus = False
        print("Product price summary is not Available", "error", error)
        caption = (
            f"ðŸŒŸ{shortTitle} \n\nâœ… Price: *Rs.{price}/-* \n\nðŸŒŸ Rating : {rating}\n\nðŸ”— {affiliateLink}"
        )
        return [caption, imageURL]

# Main Function to Control or Handle all other Functions
def handle_main_function(product_link):
    product_summary = scrape_amazon_data(product_link)
    caption = product_summary[0]
    image_url = product_summary[1]

    download_image(image_url)
    send_msg(caption)
    delete_image()

# Extract Amazon Links from Messages
def extract_amazon_links(messages):
    pattern = r"https://amzn.to/[a-zA-Z0-9]+"
    amazon_links = re.findall(pattern, messages)
    return amazon_links

print("---------------------------------------------------------------------------------")

# Some Links of code are Hidden. Because those lines are core to this project
'''


               H   H  III  DDDD   EEEE
               H   H   I   D   D  E
               HHHHH   I   D   D  EEE
               H   H   I   D   D  E
               H   H  III  DDDD   EEEE
               

'''

    if len(links) == 1:
        print("---------------------------------------------------------------------------------")
        try:
            handle_main_function(links[0])
        except Exception as e:
            print("Something is wrong")
            print(e)
    else:
        print("---------------------------------------------------------------------------------")
        print("Multiple Links or No Links")

# Run the client
client.run_until_disconnected()
